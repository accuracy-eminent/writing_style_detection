{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gutenbergpy.textget\n",
    "import re\n",
    "import string\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, RegexpTokenizer\n",
    "from plotnine import *\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in datasets\n",
    "book_contents_train = utils.load_book_contents(utils.book_authors_train)\n",
    "book_contents_test = utils.load_book_contents(utils.book_authors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "books_train_wtoks = utils.wtok_books(book_contents_train)\n",
    "books_test_wtoks = utils.wtok_books(book_contents_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 100 samples per book of around 1000 words each\n",
    "from importlib import reload\n",
    "reload(utils)\n",
    "book_samples_train = utils.get_samples(books_train_wtoks, 100, [10, 1000], random_seed=42)\n",
    "book_samples_test = utils.get_samples(books_test_wtoks, 100, [10, 1000], random_seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cd_1grams  cd_2grams  cd_3grams  ja_1grams  ja_2grams  ja_3grams  \\\n",
      "0         0.003      0.001      0.000      0.010      0.003      0.001   \n",
      "1         0.011      0.001      0.000      0.001      0.000      0.000   \n",
      "2         0.003      0.003      0.000      0.000      0.000      0.000   \n",
      "3         0.002      0.003      0.001      0.010      0.002      0.001   \n",
      "4         0.004      0.003      0.001      0.000      0.001      0.000   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1795      0.000      0.000      0.000      0.014      0.006      0.002   \n",
      "1796      0.001      0.001      0.000      0.027      0.012      0.005   \n",
      "1797      0.000      0.000      0.000      0.048      0.025      0.006   \n",
      "1798      0.000      0.000      0.001      0.070      0.012      0.002   \n",
      "1799      0.000      0.000      0.000      0.014      0.003      0.004   \n",
      "\n",
      "      hm_1grams  hm_2grams  hm_3grams  book_id  sample_num  \n",
      "0         0.000      0.001      0.000     46.0         0.0  \n",
      "1         0.000      0.000      0.000     46.0         1.0  \n",
      "2         0.004      0.000      0.000     46.0         2.0  \n",
      "3         0.000      0.001      0.000     46.0         3.0  \n",
      "4         0.000      0.002      0.001     46.0         4.0  \n",
      "...         ...        ...        ...      ...         ...  \n",
      "1795      0.002      0.002      0.000    141.0        95.0  \n",
      "1796      0.001      0.001      0.000    141.0        96.0  \n",
      "1797      0.000      0.000      0.000    141.0        97.0  \n",
      "1798      0.001      0.000      0.000    141.0        98.0  \n",
      "1799      0.000      0.000      0.000    141.0        99.0  \n",
      "\n",
      "[1800 rows x 11 columns]\n",
      "        author_name  book_id\n",
      "0   Charles Dickens       46\n",
      "1   Charles Dickens       98\n",
      "2   Charles Dickens     1400\n",
      "3   Charles Dickens      730\n",
      "4   Charles Dickens      766\n",
      "5   Charles Dickens     1023\n",
      "6   Herman Melville     2701\n",
      "7   Herman Melville    11231\n",
      "8   Herman Melville    15859\n",
      "9   Herman Melville    21816\n",
      "10  Herman Melville    34970\n",
      "11  Herman Melville    10712\n",
      "12      Jane Austen     1342\n",
      "13      Jane Austen      158\n",
      "14      Jane Austen      161\n",
      "15      Jane Austen      105\n",
      "16      Jane Austen      121\n",
      "17      Jane Austen      141\n",
      "     cd_1grams  cd_2grams  cd_3grams  ja_1grams  ja_2grams  ja_3grams  \\\n",
      "0        0.002      0.003      0.000      0.041      0.015      0.005   \n",
      "1        0.009      0.011      0.002      0.012      0.001      0.001   \n",
      "2        0.005      0.004      0.003      0.028      0.008      0.004   \n",
      "3        0.003      0.005      0.001      0.016      0.004      0.000   \n",
      "4        0.004      0.004      0.001      0.014      0.001      0.000   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "995      0.000      0.001      0.000      0.004      0.001      0.004   \n",
      "996      0.000      0.000      0.000      0.025      0.006      0.001   \n",
      "997      0.001      0.000      0.000      0.039      0.016      0.002   \n",
      "998      0.001      0.001      0.000      0.014      0.002      0.002   \n",
      "999      0.000      0.001      0.001      0.004      0.002      0.001   \n",
      "\n",
      "     hm_1grams  hm_2grams  hm_3grams  book_id  sample_num  \n",
      "0        0.000      0.000      0.001    786.0         0.0  \n",
      "1        0.000      0.001      0.000    786.0         1.0  \n",
      "2        0.002      0.001      0.000    786.0         2.0  \n",
      "3        0.001      0.000      0.000    786.0         3.0  \n",
      "4        0.000      0.000      0.000    786.0         4.0  \n",
      "..         ...        ...        ...      ...         ...  \n",
      "995      0.001      0.001      0.001   1212.0        95.0  \n",
      "996      0.000      0.001      0.000   1212.0        96.0  \n",
      "997      0.001      0.000      0.000   1212.0        97.0  \n",
      "998      0.000      0.000      0.000   1212.0        98.0  \n",
      "999      0.003      0.000      0.001   1212.0        99.0  \n",
      "\n",
      "[1000 rows x 11 columns]\n",
      "        author_name  book_id\n",
      "0   Charles Dickens    786.0\n",
      "1   Charles Dickens    580.0\n",
      "2   Charles Dickens    883.0\n",
      "3   Charles Dickens      NaN\n",
      "4   Charles Dickens      NaN\n",
      "5   Herman Melville   4045.0\n",
      "6   Herman Melville   8118.0\n",
      "7   Herman Melville   2694.0\n",
      "8   Herman Melville  13720.0\n",
      "9   Herman Melville  53861.0\n",
      "10      Jane Austen    946.0\n",
      "11      Jane Austen   1212.0\n",
      "12      Jane Austen      NaN\n",
      "13      Jane Austen      NaN\n",
      "14      Jane Austen      NaN\n"
     ]
    }
   ],
   "source": [
    "# Do feature engineering\n",
    "# Use ngram frequency as features\n",
    "# cd_1grams is the frequency of 1-grams associated with Charles Dickens, for example\n",
    "data_df_train = utils.get_data_df(book_samples_train, utils.book_authors_train)\n",
    "data_df_test = utils.get_data_df(book_samples_test, utils.book_authors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_cols = data_df_test.columns\n",
    "tgt_cols = ['author_name']\n",
    "X_train = data_df_train.drop(tgt_cols,axis=1)\n",
    "y_train = data_df_train.filter(tgt_cols).to_numpy().ravel()\n",
    "X_test = data_df_test.drop(tgt_cols,axis=1)\n",
    "y_test = data_df_test.filter(tgt_cols).to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 9)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cd_1grams',\n",
       " 'cd_2grams',\n",
       " 'cd_3grams',\n",
       " 'ja_1grams',\n",
       " 'ja_2grams',\n",
       " 'ja_3grams',\n",
       " 'hm_1grams',\n",
       " 'hm_2grams',\n",
       " 'hm_3grams']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.837\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jane Austen</th>\n",
       "      <th>Charles Dickens</th>\n",
       "      <th>Herman Melville</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jane Austen</th>\n",
       "      <td>255</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charles Dickens</th>\n",
       "      <td>81</td>\n",
       "      <td>404</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Herman Melville</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Jane Austen  Charles Dickens  Herman Melville\n",
       "Jane Austen              255               24               21\n",
       "Charles Dickens           81              404               15\n",
       "Herman Melville            4               18              178"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Charles Dickens       0.75      0.85      0.80       300\n",
      "Herman Melville       0.91      0.81      0.85       500\n",
      "    Jane Austen       0.83      0.89      0.86       200\n",
      "\n",
      "       accuracy                           0.84      1000\n",
      "      macro avg       0.83      0.85      0.84      1000\n",
      "   weighted avg       0.84      0.84      0.84      1000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jane Austen</th>\n",
       "      <th>Charles Dickens</th>\n",
       "      <th>Herman Melville</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jane Austen</th>\n",
       "      <td>255</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charles Dickens</th>\n",
       "      <td>81</td>\n",
       "      <td>404</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Herman Melville</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Jane Austen  Charles Dickens  Herman Melville\n",
       "Jane Austen              255               24               21\n",
       "Charles Dickens           81              404               15\n",
       "Herman Melville            4               18              178"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_model =  GradientBoostingClassifier()\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred = gb_model.predict(X_test)\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", acc)\n",
    "conf_matrix = pd.DataFrame(metrics.confusion_matrix(y_test, y_pred))\n",
    "conf_matrix.index = set(y_train)\n",
    "conf_matrix.columns = conf_matrix.index\n",
    "display(conf_matrix)\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81111111, 0.91666667, 0.89444444, 0.89444444, 0.91944444])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores = cross_val_score(gb_model, X_train, y_train, cv=5)\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ja_3grams</td>\n",
       "      <td>0.24418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cd_2grams</td>\n",
       "      <td>0.161869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cd_1grams</td>\n",
       "      <td>0.157717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hm_2grams</td>\n",
       "      <td>0.133258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hm_1grams</td>\n",
       "      <td>0.130017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ja_1grams</td>\n",
       "      <td>0.071564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ja_2grams</td>\n",
       "      <td>0.067519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hm_3grams</td>\n",
       "      <td>0.028722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cd_3grams</td>\n",
       "      <td>0.005154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature Importance\n",
       "5  ja_3grams    0.24418\n",
       "1  cd_2grams   0.161869\n",
       "0  cd_1grams   0.157717\n",
       "7  hm_2grams   0.133258\n",
       "6  hm_1grams   0.130017\n",
       "3  ja_1grams   0.071564\n",
       "4  ja_2grams   0.067519\n",
       "8  hm_3grams   0.028722\n",
       "2  cd_3grams   0.005154"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame([X_train.columns, gb_model.feature_importances_]).T\n",
    "feature_importances.columns = ['Feature','Importance']\n",
    "feature_importances.sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Charles Dickens</th>\n",
       "      <th>Herman Melville</th>\n",
       "      <th>Jane Austen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>786.0</td>\n",
       "      <td>4045</td>\n",
       "      <td>946.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580.0</td>\n",
       "      <td>8118</td>\n",
       "      <td>1212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>883.0</td>\n",
       "      <td>2694</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>13720</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>53861</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Charles Dickens  Herman Melville  Jane Austen\n",
       "0            786.0             4045        946.0\n",
       "1            580.0             8118       1212.0\n",
       "2            883.0             2694          NaN\n",
       "3              NaN            13720          NaN\n",
       "4              NaN            53861          NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dict([(k, pd.Series(v)) for k, v in utils.book_authors_test.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_num(data, sample_id):\n",
    "    sample_id = int(str(sample_id).split(\"_\")[0])\n",
    "\n",
    "    authors_df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in data.items()]))\n",
    "    author_name = pd.melt(authors_df).query(\"value == @sample_id\").variable.tolist()[0]\n",
    "    return ['Charles Dickens', 'Jane Austen','Herman Melville'].index(author_name)\n",
    "def stretch(arr, min_len, pad='<PAD>'):\n",
    "    return arr + (min_len-len(arr))* [pad]\n",
    "#train_data = [(stretch(words, 1000, '<PAD>'), get_author_num(utils.book_authors_train, sample_id)) for sample_id, words in book_samples_train.items()]\n",
    "#test_data = [(stretch(words, 1000, '<PAD>'), get_author_num(utils.book_authors_test, sample_id)) for sample_id, words in book_samples_test.items()]\n",
    "train_data = [(words, get_author_num(utils.book_authors_train, sample_id)) for sample_id, words in book_samples_train.items()]\n",
    "test_data = [(words, get_author_num(utils.book_authors_test, sample_id)) for sample_id, words in book_samples_test.items()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pencil-case', ',', 'a', 'pair', 'of', 'sleeve-buttons', ',', 'and', 'a']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0][-10:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_words = [word for words, _ in train_data for word in words]\n",
    "word_counts = Counter(all_words)\n",
    "vocab = {word: idx + 1 for idx, (word, count) in enumerate(word_counts.most_common(1000))}\n",
    "\n",
    "vocab['<PAD>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_df = (\n",
    "    pd.DataFrame({k: pd.Series(v) for k, v in vocab.items()})\n",
    "    .T.reset_index()\n",
    ")\n",
    "vocab_df.columns = ['name', 'num']\n",
    "vocab_df.to_csv(\"../data/vocab.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data, vocab):\n",
    "        self.data = data\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        words, label = self.data[idx]\n",
    "        word_indices = [self.vocab.get(word, 0) for word in words]\n",
    "        return torch.tensor(word_indices), torch.tensor(int(label))  # Assuming labels are integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class AuthorClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_classes):\n",
    "        super(AuthorClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        output = self.fc(lstm_out[:, -1, :])  # Take the last LSTM output for each sequence\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "710"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_dim = 64\n",
    "hidden_size = 128\n",
    "num_classes = len(set(label for _, label in train_data))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Model, loss, optimizer\n",
    "model = AuthorClassifier(vocab_size, embedding_dim, hidden_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_dataset = TextDataset(train_data, vocab)\n",
    "test_dataset = TextDataset(test_data, vocab)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Loss: 0.00010006673417337926\n",
      "Accuracy:  100.0\n",
      "1\n",
      "Loss: 4.369890660254012e-05\n",
      "Accuracy:  100.0\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    model.train()\n",
    "    loss_vals = []\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        loss_vals.append(loss.item())\n",
    "        _, pred_labels = torch.max(outputs, 1)\n",
    "        total_correct += (pred_labels == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "        optimizer.step()\n",
    "    print(\"Loss:\", np.mean(loss_vals))\n",
    "    print(\"Accuracy: \", 100 * total_correct / total_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict, \"../data/weights_new.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"../data/nn.pth\")())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 79.40%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = total_correct / total_samples\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
