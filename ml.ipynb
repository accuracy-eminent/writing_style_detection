{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gutenbergpy.textget\n",
    "import re\n",
    "import string\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, RegexpTokenizer\n",
    "from plotnine import *\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in datasets\n",
    "book_authors_all = utils.get_book_authors_all()\n",
    "book_contents = utils.load_book_contents(book_authors_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "books_wtoks = utils.wtok_books(book_contents)\n",
    "books_stoks = utils.stok_books(book_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 100 samples per book of 1000 words each\n",
    "from importlib import reload\n",
    "reload(utils)\n",
    "book_samples = utils.get_samples(books_wtoks, 100, 1000, random_seed=42)\n",
    "samples_df = pd.DataFrame(book_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(book_samples['46_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cd_1grams</th>\n",
       "      <th>cd_2grams</th>\n",
       "      <th>cd_3grams</th>\n",
       "      <th>ja_1grams</th>\n",
       "      <th>ja_2grams</th>\n",
       "      <th>ja_3grams</th>\n",
       "      <th>hm_1grams</th>\n",
       "      <th>hm_2grams</th>\n",
       "      <th>hm_3grams</th>\n",
       "      <th>author_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Charles Dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Charles Dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Charles Dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Charles Dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Charles Dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Jane Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Jane Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Jane Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Jane Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Jane Austen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2800 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cd_1grams  cd_2grams  cd_3grams  ja_1grams  ja_2grams  ja_3grams  \\\n",
       "0         0.002      0.001      0.000      0.009      0.001      0.000   \n",
       "1         0.011      0.001      0.000      0.000      0.000      0.000   \n",
       "2         0.003      0.002      0.000      0.000      0.000      0.000   \n",
       "3         0.001      0.001      0.000      0.009      0.002      0.001   \n",
       "4         0.001      0.002      0.000      0.000      0.001      0.000   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2795      0.000      0.000      0.000      0.000      0.000      0.001   \n",
       "2796      0.000      0.000      0.000      0.025      0.004      0.001   \n",
       "2797      0.001      0.000      0.000      0.036      0.011      0.001   \n",
       "2798      0.001      0.001      0.000      0.009      0.001      0.000   \n",
       "2799      0.000      0.001      0.001      0.003      0.002      0.000   \n",
       "\n",
       "      hm_1grams  hm_2grams  hm_3grams      author_name  \n",
       "0         0.000      0.001      0.000  Charles Dickens  \n",
       "1         0.000      0.000      0.000  Charles Dickens  \n",
       "2         0.003      0.000      0.000  Charles Dickens  \n",
       "3         0.000      0.001      0.000  Charles Dickens  \n",
       "4         0.000      0.002      0.001  Charles Dickens  \n",
       "...         ...        ...        ...              ...  \n",
       "2795      0.000      0.001      0.001      Jane Austen  \n",
       "2796      0.000      0.001      0.000      Jane Austen  \n",
       "2797      0.000      0.000      0.000      Jane Austen  \n",
       "2798      0.000      0.000      0.000      Jane Austen  \n",
       "2799      0.000      0.000      0.000      Jane Austen  \n",
       "\n",
       "[2800 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do feature engineering\n",
    "# Use ngram frequency as features\n",
    "# cd_1grams is the frequency of 1-grams associated with Charles Dickens, for example\n",
    "def get_data_df(book_samples, book_authors):\n",
    "    ref_grams = {}\n",
    "    ref_grams[1] = {\n",
    "        'cd': [('t',), ('don',), ('boy',), ('until',), ('stopped',), ('hair',), ('d',), ('streets',), ('shook',), ('shaking',)],\n",
    "        'ja':[('her',), ('she',), ('She',), ('Mrs.',), ('herself',), ('sister',), ('father',), ('Lady',), ('wish',), ('Sir',)],\n",
    "        'hm':[('sea',), ('strange',), ('THE',), ('Nor',), ('board',), ('ye',), ('ere',), ('peculiar',), ('concerning',), ('original',)]\n",
    "    }\n",
    "    ref_grams[2] = {\n",
    "        'cd':[('’', 't'), ('don', '’'), (',', 'Mr.'), ('said', 'the'), ('his', 'head'), ('the', 'fire'), (',', 'looking'), ('I', 'said'), ('s', 'a'), ('“', 'Now')],\n",
    "        'ja':[('.', 'She'), (',', 'she'), ('of', 'her'), ('she', 'had'), ('could', 'not'), ('to', 'her'), ('she', 'was'), ('that', 'she'), ('do', 'not'), ('she', 'could')],\n",
    "        'hm':[(',', 'then'), (',', 'yet'), (';', 'in'), ('.', 'Nor'), ('so', 'that'), ('when', ','), ('.', 'Some'), ('though', ','), (';', 'while'), ('.', 'Upon')]\n",
    "    }\n",
    "    ref_grams[3] = {\n",
    "        'cd': [('don', '’', 't'), ('!', '”', 'said'), ('?', '”', 'said'), ('’', 's', 'a'), ('.', '“', 'Now'), ('.', 'I', 'had'), ('as', 'if', 'he'), ('“', 'Now', ','), ('he', 'said', ','), ('.', '“', 'Yes')],\n",
    "        'ja': [(',', 'however', ','), ('I', 'am', 'sure'), ('I', 'do', 'not'), (',', 'and', 'she'), ('.', 'She', 'was'), ('she', 'could', 'not'), ('.', 'She', 'had'), (',', 'she', 'was'), (';', 'and', 'she'), ('“', 'Oh', '!')],\n",
    "        'hm': [(',', 'then', ','), (',', 'who', ','), ('.', 'But', 'the'), ('“', 'I', 'would'), (',', 'like', 'the'), ('that', ',', 'in'), (',', 'that', 'in'), ('answer', '.', '“'), ('out', 'of', 'sight'), (',', 'in', 'some')]\n",
    "    }\n",
    "    data_dict = {}\n",
    "    for sample_id, words in book_samples.items():\n",
    "        sample_row = {}\n",
    "        get_ngrams = lambda words, gram_length: pd.Series(sorted(ngrams(words, gram_length))).value_counts()\n",
    "        top_grams = {}\n",
    "        # Calculate 1 to 3-grarms\n",
    "        for gram_length in range(1, 4):\n",
    "            top_grams[gram_length] = get_ngrams(words, gram_length)\n",
    "        # Find the number of reference ngrams by author in each sample\n",
    "        for author in ref_grams[1].keys():\n",
    "            for gram_length in range(1, 4):\n",
    "                top_grams_count = top_grams[gram_length]\n",
    "                # Uese only the first 5 ngrams\n",
    "                author_ref_grams = ref_grams[gram_length][author][0:5]\n",
    "                author_grams_count = top_grams_count.reindex(author_ref_grams)\n",
    "                # Normalize it by the length of the text\n",
    "                sample_row[f'{author}_{gram_length}grams'] = author_grams_count.sum() / len(words)\n",
    "        data_dict[sample_id] = sample_row\n",
    "    # Create the initial data frame\n",
    "    data_df = pd.DataFrame(data_dict).T\n",
    "    data_df = (\n",
    "        data_df\n",
    "        .reset_index()\n",
    "        .rename(columns={'index':'sample_id'})\n",
    "    )\n",
    "    # Clean data, attack to book authors \n",
    "    data_df = (\n",
    "        data_df\n",
    "        .assign(book_id=lambda x: x.sample_id.str.split(\"_\").apply(lambda y: y[0]).astype(float))\n",
    "        .assign(sample_num=lambda x: x.sample_id.str.split(\"_\").apply(lambda y: y[1]).astype(float))\n",
    "        .drop('sample_id', axis=1)\n",
    "    )\n",
    "    book_authors_df = pd.melt(pd.DataFrame.from_dict({k:pd.Series(v) for k, v in book_authors.items()}))\n",
    "    book_authors_df.columns = ['author_name', 'book_id']\n",
    "    data_df = data_df.merge(book_authors_df, on='book_id', how='left')\n",
    "    data_df = data_df.drop(['book_id','sample_num'], axis=1)\n",
    "    return data_df\n",
    "    #base_df = pd.DataFrame(pd.Series(book_samples)).reset_index()\n",
    "    #base_df.columns = ['sample','words']\n",
    "data_df = get_data_df(book_samples, book_authors_all)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_cols = data_df.columns\n",
    "tgt_cols = ['author_name']\n",
    "X = data_df.drop(tgt_cols,axis=1)\n",
    "y = data_df.filter(tgt_cols).to_numpy().ravel()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size = 0.2,\n",
    "    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8928571428571429\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jane Austen</th>\n",
       "      <th>Herman Melville</th>\n",
       "      <th>Charles Dickens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jane Austen</th>\n",
       "      <td>149</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Herman Melville</th>\n",
       "      <td>15</td>\n",
       "      <td>208</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charles Dickens</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Jane Austen  Herman Melville  Charles Dickens\n",
       "Jane Austen              149               17               12\n",
       "Herman Melville           15              208                3\n",
       "Charles Dickens            7                6              143"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Charles Dickens       0.87      0.84      0.85       178\n",
      "Herman Melville       0.90      0.92      0.91       226\n",
      "    Jane Austen       0.91      0.92      0.91       156\n",
      "\n",
      "       accuracy                           0.89       560\n",
      "      macro avg       0.89      0.89      0.89       560\n",
      "   weighted avg       0.89      0.89      0.89       560\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jane Austen</th>\n",
       "      <th>Herman Melville</th>\n",
       "      <th>Charles Dickens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jane Austen</th>\n",
       "      <td>149</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Herman Melville</th>\n",
       "      <td>15</td>\n",
       "      <td>208</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charles Dickens</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Jane Austen  Herman Melville  Charles Dickens\n",
       "Jane Austen              149               17               12\n",
       "Herman Melville           15              208                3\n",
       "Charles Dickens            7                6              143"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_model =  GradientBoostingClassifier()\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred = gb_model.predict(X_test)\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", acc)\n",
    "conf_matrix = pd.DataFrame(metrics.confusion_matrix(y_test, y_pred))\n",
    "conf_matrix.index = set(y_train)\n",
    "conf_matrix.columns = conf_matrix.index\n",
    "display(conf_matrix)\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.890625  , 0.82366071, 0.83705357, 0.86830357, 0.875     ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores = cross_val_score(gb_model, X_train, y_train, cv=5)\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12752857, 0.21378603, 0.00882246, 0.18125047, 0.17196394,\n",
       "       0.06115826, 0.12355298, 0.06663789, 0.0452994 ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DataFrame.sort_values() missing 1 required positional argument: 'by'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: DataFrame.sort_values() missing 1 required positional argument: 'by'"
     ]
    }
   ],
   "source": [
    "X_train.sort_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
