{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gutenbergpy.textget\n",
    "import re\n",
    "import string\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, RegexpTokenizer\n",
    "from plotnine import *\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in datasets\n",
    "book_authors_all = utils.get_book_authors_all()\n",
    "book_contents = utils.load_book_contents(book_authors_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "books_wtoks = utils.wtok_books(book_contents)\n",
    "books_stoks = utils.stok_books(book_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 100 samples per book of around 1000 words each\n",
    "from importlib import reload\n",
    "reload(utils)\n",
    "book_samples = utils.get_samples(books_wtoks, 100, [900, 1100], random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cd_1grams</th>\n",
       "      <th>cd_2grams</th>\n",
       "      <th>cd_3grams</th>\n",
       "      <th>ja_1grams</th>\n",
       "      <th>ja_2grams</th>\n",
       "      <th>ja_3grams</th>\n",
       "      <th>hm_1grams</th>\n",
       "      <th>hm_2grams</th>\n",
       "      <th>hm_3grams</th>\n",
       "      <th>author_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010978</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Charles Dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003282</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Charles Dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001838</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008272</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Charles Dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>Charles Dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Charles Dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029883</td>\n",
       "      <td>0.007471</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Jane Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Jane Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.031792</td>\n",
       "      <td>0.004817</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Jane Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.030681</td>\n",
       "      <td>0.002876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Jane Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Jane Austen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2800 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cd_1grams  cd_2grams  cd_3grams  ja_1grams  ja_2grams  ja_3grams  \\\n",
       "0      0.000000   0.001996   0.000000   0.010978   0.001996   0.000000   \n",
       "1      0.003282   0.002188   0.000000   0.000000   0.000000   0.000000   \n",
       "2      0.001838   0.002757   0.000000   0.008272   0.001838   0.000919   \n",
       "3      0.000979   0.001959   0.000000   0.000000   0.000979   0.000000   \n",
       "4      0.000000   0.002053   0.000000   0.000000   0.000000   0.001027   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2795   0.000000   0.000000   0.000000   0.029883   0.007471   0.003202   \n",
       "2796   0.000985   0.001970   0.000000   0.005911   0.000000   0.000000   \n",
       "2797   0.000963   0.000000   0.000963   0.031792   0.004817   0.000963   \n",
       "2798   0.000959   0.000000   0.000959   0.030681   0.002876   0.000000   \n",
       "2799   0.000000   0.000000   0.000000   0.003910   0.001955   0.000978   \n",
       "\n",
       "      hm_1grams  hm_2grams  hm_3grams      author_name  \n",
       "0      0.000000   0.000998   0.000000  Charles Dickens  \n",
       "1      0.003282   0.000000   0.000000  Charles Dickens  \n",
       "2      0.000000   0.000919   0.000000  Charles Dickens  \n",
       "3      0.000000   0.001959   0.000979  Charles Dickens  \n",
       "4      0.002053   0.001027   0.000000  Charles Dickens  \n",
       "...         ...        ...        ...              ...  \n",
       "2795   0.000000   0.000000   0.000000      Jane Austen  \n",
       "2796   0.004926   0.000000   0.000000      Jane Austen  \n",
       "2797   0.000000   0.000000   0.000000      Jane Austen  \n",
       "2798   0.000000   0.000000   0.000000      Jane Austen  \n",
       "2799   0.000000   0.000000   0.000000      Jane Austen  \n",
       "\n",
       "[2800 rows x 10 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do feature engineering\n",
    "# Use ngram frequency as features\n",
    "# cd_1grams is the frequency of 1-grams associated with Charles Dickens, for example\n",
    "def get_data_df(book_samples, book_authors):\n",
    "    ref_grams = {}\n",
    "    ref_grams[1] = {\n",
    "        'cd': [('t',), ('don',), ('boy',), ('until',), ('stopped',), ('hair',), ('d',), ('streets',), ('shook',), ('shaking',)],\n",
    "        'ja':[('her',), ('she',), ('She',), ('Mrs.',), ('herself',), ('sister',), ('father',), ('Lady',), ('wish',), ('Sir',)],\n",
    "        'hm':[('sea',), ('strange',), ('THE',), ('Nor',), ('board',), ('ye',), ('ere',), ('peculiar',), ('concerning',), ('original',)]\n",
    "    }\n",
    "    ref_grams[2] = {\n",
    "        'cd':[('’', 't'), ('don', '’'), (',', 'Mr.'), ('said', 'the'), ('his', 'head'), ('the', 'fire'), (',', 'looking'), ('I', 'said'), ('s', 'a'), ('“', 'Now')],\n",
    "        'ja':[('.', 'She'), (',', 'she'), ('of', 'her'), ('she', 'had'), ('could', 'not'), ('to', 'her'), ('she', 'was'), ('that', 'she'), ('do', 'not'), ('she', 'could')],\n",
    "        'hm':[(',', 'then'), (',', 'yet'), (';', 'in'), ('.', 'Nor'), ('so', 'that'), ('when', ','), ('.', 'Some'), ('though', ','), (';', 'while'), ('.', 'Upon')]\n",
    "    }\n",
    "    ref_grams[3] = {\n",
    "        'cd': [('don', '’', 't'), ('!', '”', 'said'), ('?', '”', 'said'), ('’', 's', 'a'), ('.', '“', 'Now'), ('.', 'I', 'had'), ('as', 'if', 'he'), ('“', 'Now', ','), ('he', 'said', ','), ('.', '“', 'Yes')],\n",
    "        'ja': [(',', 'however', ','), ('I', 'am', 'sure'), ('I', 'do', 'not'), (',', 'and', 'she'), ('.', 'She', 'was'), ('she', 'could', 'not'), ('.', 'She', 'had'), (',', 'she', 'was'), (';', 'and', 'she'), ('“', 'Oh', '!')],\n",
    "        'hm': [(',', 'then', ','), (',', 'who', ','), ('.', 'But', 'the'), ('“', 'I', 'would'), (',', 'like', 'the'), ('that', ',', 'in'), (',', 'that', 'in'), ('answer', '.', '“'), ('out', 'of', 'sight'), (',', 'in', 'some')]\n",
    "    }\n",
    "    data_dict = {}\n",
    "    for sample_id, words in book_samples.items():\n",
    "        sample_row = {}\n",
    "        get_ngrams = lambda words, gram_length: pd.Series(sorted(ngrams(words, gram_length))).value_counts()\n",
    "        top_grams = {}\n",
    "        # Calculate 1 to 3-grarms\n",
    "        for gram_length in range(1, 4):\n",
    "            top_grams[gram_length] = get_ngrams(words, gram_length)\n",
    "        # Find the number of reference ngrams by author in each sample\n",
    "        for author in ref_grams[1].keys():\n",
    "            for gram_length in range(1, 4):\n",
    "                top_grams_count = top_grams[gram_length]\n",
    "                # Uese only the first 5 ngrams\n",
    "                author_ref_grams = ref_grams[gram_length][author][0:5]\n",
    "                author_grams_count = top_grams_count.reindex(author_ref_grams)\n",
    "                # Normalize it by the length of the text\n",
    "                sample_row[f'{author}_{gram_length}grams'] = author_grams_count.sum() / len(words)\n",
    "        data_dict[sample_id] = sample_row\n",
    "    # Create the initial data frame\n",
    "    data_df = pd.DataFrame(data_dict).T\n",
    "    data_df = (\n",
    "        data_df\n",
    "        .reset_index()\n",
    "        .rename(columns={'index':'sample_id'})\n",
    "    )\n",
    "    # Clean data, attack to book authors \n",
    "    data_df = (\n",
    "        data_df\n",
    "        .assign(book_id=lambda x: x.sample_id.str.split(\"_\").apply(lambda y: y[0]).astype(float))\n",
    "        .assign(sample_num=lambda x: x.sample_id.str.split(\"_\").apply(lambda y: y[1]).astype(float))\n",
    "        .drop('sample_id', axis=1)\n",
    "    )\n",
    "    book_authors_df = pd.melt(pd.DataFrame.from_dict({k:pd.Series(v) for k, v in book_authors.items()}))\n",
    "    book_authors_df.columns = ['author_name', 'book_id']\n",
    "    data_df = data_df.merge(book_authors_df, on='book_id', how='left')\n",
    "    data_df = data_df.drop(['book_id','sample_num'], axis=1)\n",
    "    return data_df\n",
    "    #base_df = pd.DataFrame(pd.Series(book_samples)).reset_index()\n",
    "    #base_df.columns = ['sample','words']\n",
    "data_df = get_data_df(book_samples, book_authors_all)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_cols = data_df.columns\n",
    "tgt_cols = ['author_name']\n",
    "X = data_df.drop(tgt_cols,axis=1)\n",
    "y = data_df.filter(tgt_cols).to_numpy().ravel()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size = 0.2,\n",
    "    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8392857142857143\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jane Austen</th>\n",
       "      <th>Herman Melville</th>\n",
       "      <th>Charles Dickens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jane Austen</th>\n",
       "      <td>145</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Herman Melville</th>\n",
       "      <td>28</td>\n",
       "      <td>189</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charles Dickens</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Jane Austen  Herman Melville  Charles Dickens\n",
       "Jane Austen              145               25                8\n",
       "Herman Melville           28              189                9\n",
       "Charles Dickens           11                9              136"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Charles Dickens       0.79      0.81      0.80       178\n",
      "Herman Melville       0.85      0.84      0.84       226\n",
      "    Jane Austen       0.89      0.87      0.88       156\n",
      "\n",
      "       accuracy                           0.84       560\n",
      "      macro avg       0.84      0.84      0.84       560\n",
      "   weighted avg       0.84      0.84      0.84       560\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jane Austen</th>\n",
       "      <th>Herman Melville</th>\n",
       "      <th>Charles Dickens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jane Austen</th>\n",
       "      <td>145</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Herman Melville</th>\n",
       "      <td>28</td>\n",
       "      <td>189</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charles Dickens</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Jane Austen  Herman Melville  Charles Dickens\n",
       "Jane Austen              145               25                8\n",
       "Herman Melville           28              189                9\n",
       "Charles Dickens           11                9              136"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_model =  GradientBoostingClassifier()\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred = gb_model.predict(X_test)\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", acc)\n",
    "conf_matrix = pd.DataFrame(metrics.confusion_matrix(y_test, y_pred))\n",
    "conf_matrix.index = set(y_train)\n",
    "conf_matrix.columns = conf_matrix.index\n",
    "display(conf_matrix)\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85044643, 0.84598214, 0.85044643, 0.859375  , 0.87053571])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores = cross_val_score(gb_model, X_train, y_train, cv=5)\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13251845, 0.24179505, 0.00605513, 0.22491354, 0.15697871,\n",
       "       0.06070813, 0.08819838, 0.05226396, 0.03656864])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_model.feature_importances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
